# ğŸ–¼ï¸ Image Caption Generator

A deep-learning based project that automatically generates captions for images using a CNN + LSTM model.

---

## **ğŸš€ Project Overview**

The Image Caption Generator takes an image as input and generates a meaningful sentence describing the content of the image.
It combines:

- CNN (VGG16) â†’ for image feature extraction
- LSTM (RNN) â†’ for sequence generation (captions)
- Tokenizer + Embedding Layer â†’ for text processing
- Greedy Search â†’ for caption generation
- The project is trained on the Flickr30k dataset.

---

## **Dataset**

- Flickr30k: 30,000 images
- Each image has 5 captions

---

## **ğŸ“‚ Project Structure**

```
ğŸ“ Image-Caption-Generator
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ captions.txt             # file containing captions
â”‚
â”œâ”€â”€ extra/
â”‚   â”œâ”€â”€ calc_bleu.py             # to calculate bleu score
â”‚   â”œâ”€â”€ mapping.py               # file to get mapping.pkl from captions.txt
â”‚   â””â”€â”€ test_image.py            # file to test an image
â”‚
â”œâ”€â”€ images                       # Folder for visual outputs and graphs
â”‚
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ best_model.keras         # saved main model
â”‚   â”œâ”€â”€ caption_config.pkl
â”‚   â”œâ”€â”€ features.pkl
â”‚   â”œâ”€â”€ mapping.pkl
â”‚   â”œâ”€â”€ max_length.pkl
â”‚   â”œâ”€â”€ tokenizer.pkl
â”‚   â””â”€â”€ vocab_size.pkl
â”‚
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ css/
â”‚   â”‚   â””â”€â”€ style.css            # Stylesheet for frontend design
â”‚   â””â”€â”€ js/ 
â”‚       â””â”€â”€ script.js            # script for some effects
â”‚
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html               # Main HTML page for user input and results
â”‚
â”œâ”€â”€ venv                         # Virtual environment directory for dependency isolation
â”‚
â”œâ”€â”€ app.py                       # Flask web app
|
â”œâ”€â”€ img-cap-30k.ipynb            # Notebook for training, evaluating, and saving the model
|
â”œâ”€â”€ README.md                    # Project description, setup instructions, usage guide
|
â””â”€â”€requirements.txt              # Complete list of required Python packages
```

---

## **ğŸ§  How It Works**

- User uploads an image
- CNN extracts a 2048-dim feature vector
- The LSTM model takes this vector + the caption words
- The model predicts the next word until <endseq>
- Final caption is displayed on the webpage

---

## **Usage**

1. Install dependencies:

```bash
pip install -r requirements.txt
```

2. Run the Flask app:

```bash
python app.py
```

3. Open your browser and go to:

```
http://127.0.0.1:5000
```

4. Upload an image:

- Click on 'Choose File'

5. Get caption:

- Click on 'Generate Caption'

---

## **Example Output**

![Webpage](./images/webpage.png)

---

## **Model**

![Model](./images/model.png)

---

## **BLEU Score**

![BLEU](./images/BLEU.png)

---

## **Training Configuration**

- Loss Function: Categorical Crossentropy
- Optimizer: Adam
- Batch Size: 32
- Epochs: 25
- Total training time: 2 hours 50 minutes 55 seconds

### **Training**

![Training](./images/training.png)

---

## **ğŸ“œ License**

This project is for academic and learning purposes.

---

## **Author**

Devansh Khanduri
